{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxTnbaB2TRmt"
   },
   "source": [
    "# PyTorch Computer Vision Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4uHyTPtTb5C"
   },
   "source": [
    "0. Computer Vision Libraries in PyTorch\n",
    "\n",
    "1. `torchvision` - base domain library for PyTorch computer vision tasks\n",
    "2. `torchvision.datasets` - get datasets and data loading function for computer vision\n",
    "3. `torchvision.models` - get pretrained computer vision models that you can leverate for your own tasks\n",
    "4. `torchvision.transforms` - functions for manipulating your vision (images) to be sutibale for use with an ML model.\n",
    "5. `torch.utils.data.Dataset` - base class for PyTorch datasets.\n",
    "6. `torch.utils.data.DataLoader` - Creates a Python iterabe over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5WkdYqoUNmo"
   },
   "outputs": [],
   "source": [
    "## 1. Import pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z70__YaMU7Sc"
   },
   "source": [
    "## 2. Getting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdthcRHsVHcb"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data to\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eZ0KT4GWHQ8"
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y539aEkXWaKg"
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caaNK9WUWcNI"
   },
   "outputs": [],
   "source": [
    "# See the first training sample\n",
    "image, label = train_data[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-ZiJrerW6aX"
   },
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgYIwGT9W9pV"
   },
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKD-AIHgXMmU"
   },
   "outputs": [],
   "source": [
    "class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9PpVBgAXT4G"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFeAJRguXdZv"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NZ7D6BSXq_R"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze(), cmap=\"gray\");\n",
    "plt.title(class_names[label]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfWGon15X6bx"
   },
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9CdjVAFYPQs"
   },
   "outputs": [],
   "source": [
    "train_data.targets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_YMZ0QfYvSs"
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBteNv19Yyey"
   },
   "outputs": [],
   "source": [
    "torch.randint(0, len(train_data), size=[1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFyoB9IuYYi-"
   },
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows*cols+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaBBFvnWZtBx"
   },
   "source": [
    "## 3. Prepare a DataLoader\n",
    "\n",
    "Right now, our data is in the form of PyTorch datasets.\n",
    "\n",
    "Specifically, we want to turn (convert) our data into batches (mini-batches).\n",
    "\n",
    "Why would we do this?\n",
    "\n",
    "1. It is more computationlly efficient, as in, your computing hardware my not be able to look at (store in memory) 60000 images in one hit. So we break down to 32 images at a time (batch size of 32)\n",
    "2. It gives our neural network more chances to update its gradients per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7NQpnHcaRD4"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h41oPNLNbUsE"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn dataset into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XesPKMQc0d8"
   },
   "outputs": [],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQUq1ZvUdX0e"
   },
   "outputs": [],
   "source": [
    "1875 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0rfYl3Sdbmv"
   },
   "outputs": [],
   "source": [
    "313 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkyQpY8LdlS2"
   },
   "outputs": [],
   "source": [
    "10000 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-LaTBXTd1e9"
   },
   "outputs": [],
   "source": [
    "batch_images, batch_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAhKDGqoeOUh"
   },
   "outputs": [],
   "source": [
    "batch_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-rnqyfXeaW2"
   },
   "outputs": [],
   "source": [
    "batch_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkA6fpdSexSX"
   },
   "outputs": [],
   "source": [
    "len(batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npdjHSuie0ks"
   },
   "outputs": [],
   "source": [
    "torch.randint(0, len(batch_images), size=[1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foHpHMmNfLVl"
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjKzr8cJensC"
   },
   "outputs": [],
   "source": [
    "# Visualize one sample from the batch\n",
    "# torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(batch_images), size=[1]).item()\n",
    "img, label = batch_images[random_idx], batch_labels[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjIVciPifsD7"
   },
   "source": [
    "## 4. Model 0: Build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JW6c26lYgl6t"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLoQJaPJgwNI"
   },
   "outputs": [],
   "source": [
    "my_flatten_layer = nn.Flatten()\n",
    "\n",
    "my_flatten_layer(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOUwnFNchBml"
   },
   "outputs": [],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aC8FTWJ5hJen"
   },
   "outputs": [],
   "source": [
    "plt.imshow(my_flatten_layer(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5D_W7kIhv0I"
   },
   "outputs": [],
   "source": [
    "print(f\"Image before flattening {image.shape}\")\n",
    "print(f\"Image after flatting: {my_flatten_layer(image).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD2NM02XiwKU"
   },
   "outputs": [],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daV74svRfxFw"
   },
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape) # one neruon per class (so we need a probability for each class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x) # x is input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AKMvlovj6xT"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTModelV0(input_shape=784,\n",
    "                            hidden_units=10,\n",
    "                            output_shape=len(class_names))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDVsZEtRkb0Y"
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFTKVp7ukvnY"
   },
   "outputs": [],
   "source": [
    "dummy_x = image.unsqueeze(dim=0)\n",
    "\n",
    "model(dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuD8WUUAlbhi"
   },
   "source": [
    "## 3.1 Setup loss, optimizer and evalution metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxVnGXnFmX8x"
   },
   "outputs": [],
   "source": [
    "next(iter(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42ZB3PLKlik9"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1Bg2wpRnEp4"
   },
   "outputs": [],
   "source": [
    "my_tensor_A = torch.tensor([1, 2, 3, 4])\n",
    "my_tensor_B = torch.tensor([10, 2, 40, 4])\n",
    "\n",
    "torch.eq(my_tensor_A, my_tensor_B).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxw6nC8YmuSC"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDlCEtxvn525"
   },
   "source": [
    "## 3. Creating a function to time our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bt-LIxOJoBWw"
   },
   "source": [
    "Machine Learning is very experimental.\n",
    "\n",
    "Two of the main things you'll often track are:\n",
    "1. The model's performance (loss and accuracy)\n",
    "2. How fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-Vmc97Nofuo"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "\n",
    "    \"\"\"Prints difference between start and end time.\"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train traim on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmHNlkVhpDxW"
   },
   "outputs": [],
   "source": [
    "start_time = timer()\n",
    "# Some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time,\n",
    "                 end=end_time,\n",
    "                 device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "347r1gejpXfc"
   },
   "source": [
    "## 3.3 Creating a training loop and testing loop and training the model on batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5rZYM25qbyw"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jZzP1UCqfPR"
   },
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Nw6APjgph2G"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# Create a training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n------\")\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    #Training\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # Accumualively increase the loss\n",
    "\n",
    "        # 3. Optimizer zero gard\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward (backprogagation algorithm)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Gradient Descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out what is happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "\n",
    "    # Divide (Normalize - Scale) the train loss by length of train_dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X_test)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "            # 3. Calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test,\n",
    "                                    y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Normalize (Scale) the test loss average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        # Normalize (Scale) the test acc average per batch\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    # Print out what is happeing\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_on_cpu,\n",
    "                                          end=train_time_end_on_cpu,\n",
    "                                          device=str(next(model.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF8gWxgAJdhA"
   },
   "outputs": [],
   "source": [
    "# Device Agnostic Code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXgyldhAJR1a"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data: list,\n",
    "                     device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare the sample (add a batch dimension and pass to target device)\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "\n",
    "            # Forward pass (model outputs raw logits)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probabilities)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "\n",
    "            # Get pred prob off the GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bslaDo6XKwOR"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first sample shape\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcWhbWQXLT3v"
   },
   "outputs": [],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHQaqtS8LfPc"
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4rR62yGLp2_"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred_probs = make_predictions(model=model,\n",
    "                              data=test_samples)\n",
    "\n",
    "# View first two predictions probabilities\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWa8Ov1aMCPs"
   },
   "outputs": [],
   "source": [
    "# Convert prediction probabilities into labels\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_h8OnzCNGUw"
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOlWlN_vNUaG"
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lgX6ldkMfVi"
   },
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Create subplot\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "    # Plot the target image\n",
    "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "    # Find the prediction (in text form, e.g. \"Sandal\" or \"T-Shirt\")\n",
    "    pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "    # Get the truth label (in text form)\n",
    "    truth_label = class_names[test_labels[i]]\n",
    "\n",
    "    # Create a title for the plot\n",
    "    title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "\n",
    "    # Check for equality between pred and truth and change the color of title text\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=10, c=\"g\")\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=10, c=\"r\")\n",
    "\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrtMxqgROI0o"
   },
   "source": [
    "# Making confusion matrix for further prediction evaluation\n",
    "\n",
    "1. A confusion matrix is a fantastic way to visualize your classification model performance\n",
    "2. Make a confusion matrix `torchmetrics.ConfusionMatrix`\n",
    "3. Plot the confusion matrix using `mlxtend.plotting.plot_confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEa3E1ETOdof"
   },
   "outputs": [],
   "source": [
    "# Import tqdm.auto\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with our trained model on the test dataset\n",
    "y_preds = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making Predictions...\"):\n",
    "        # Send the data to the device and target to target deivce\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Do the forward passs\n",
    "        y_logit = model(X)\n",
    "\n",
    "        # Turn prediction from logits -> prediction probabilities -> prediction labels\n",
    "        y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
    "\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "\n",
    "# Concatenate list of predictions into a tensor\n",
    "print(y_preds)\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "y_pred_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qs2tLN6BQPHP"
   },
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNkLy76fQWOH"
   },
   "outputs": [],
   "source": [
    "mlxtend.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_TiSIMHQg2V"
   },
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GvGgpPtQYAn"
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSdp6lWeRqKi"
   },
   "outputs": [],
   "source": [
    "test_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akUcukPIR5mY"
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZLvveDXRHqc"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 1. Setup confusion matrix instance and compare between predictions and targets (labels)\n",
    "confmat = ConfusionMatrix(num_classes=len(class_names),\n",
    "                          task=\"MULTICLASS\")\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
